<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0">
    <title>Splinter's Core, Benchmarks &amp; Code Walkthrough - Splinter Vector KV Substrate</title>
    <meta name="color-scheme" content="dark">
    <meta name="google-site-verification" content="cFJqGxOZGxw1APr0yrQthB4Ml5vFuMNBu39xMS4BYJI">
    <link rel="stylesheet" media="(prefers-color-scheme:dark)" href="https://cdn.jsdelivr.net/npm/@shoelace-style/shoelace@2.20.1/cdn/themes/dark.css" onload="document.documentElement.classList.add('sl-theme-dark');">
    <link rel="stylesheet" href="/style.css">
    <link rel="canonical" href="https://splinterhq.github.io/core/">
    <script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js">
    </script>
  <meta property="og:type" content="website">
<meta property="og:site_name" content="Splinter Vector KV Substrate">
<meta property="og:locale" content="en">
<meta property="og:description" content="Explore the core architecture, C code examples, and performance benchmarks of Splinter, including its application as an LLM semantic hippocampus.">
<meta property="og:url" content="https://splinterhq.github.io/core/">
<meta property="og:image" content="https://splinterhq.github.io/uploads/favicon.svg">
<meta name="twitter:card" content="summary">
<meta name="description" content="Explore the core architecture, C code examples, and performance benchmarks of Splinter, including its application as an LLM semantic hippocampus.">
<meta name="keywords" content="Splinter Core, C Programming, Memory Benchmarks, Lock-Free Architecture, Retrieval-Augmented Generation">
<meta name="robots" content="index, follow">
<meta name="generator" content="Lume 3.1.1">
<link rel="icon" sizes="32x32" href="/favicon.ico">
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" sizes="any" href="/uploads/favicon.svg" type="image/svg+xml">
</head>
  <body>
    <main class="container">
      <nav class="top-nav" id="nav">
        <a href="/">INTRO</a>
        <a href="/core">CORE</a>
        <a href="/cli">CLI</a>
        <a href="/shards">SHARDS</a>
        <a href="/bindings">BINDINGS</a>
        <a href="https://github.com/splinterhq/libsplinter/tree/main" target="_blank">CODE</a>
      </nav>
      <div style="clear: both"></div>
      <h1>Splinter's Core, Benchmarks &amp; Code Walkthrough</h1>
<h2>"Core" Means <code>splinter.c</code> and <code>splinter.h</code> only.</h2>
<p>Philosophically, Splinter is built under the following constraints:</p>
<ol>
<li>It is not a database; it is an active storage substrate. Clients do all
calculating.</li>
<li>The main hot path of the code should strive to fit in a modern processor's
instruction cache.</li>
</ol>
<p>This set of constraints has kept the core library very lean, currently at around
845 lines of actual code, less if you remove support for embeddings, even less
if you take out the bitwise operators if you don't need them, etc. It's designed
to be embedded and customized. Splinter provides a stable, high-speed substrate
in less code than most line editors occupy.</p>
<h3>Embedding Splinter</h3>
<p>You have the option to link against <code>libsplinter.a</code> or <code>libsplinter_p.a</code> if you
have them in your linker path. You also have the option of just adding
<code>splinter.c</code> as a dependency and including its header file, <code>splinter.h</code>, like
any other tiny C library.</p>
<p>It's recommended that you first make a copy of them and then <em><strong>take out</strong></em> any
of the public API functions and forward declarations that you don't use for
maximum efficiency; the smaller it gets, the more likely it will be optimally
cached by the CPU.</p>
<p>Leave the originals as-is, so you can still build and use the CLI to manage the
stores. Additionally, <strong>double check alignment at 64 bytes</strong> (there's a test for
that) if you do anything to the slot structures.</p>
<h2>Benchmarks</h2>
<p>All tests were conducted on a Tiger Lake (i3-1115G4) with 6GB total usable RAM
while performing other experiments (worst case workday):</p>
<table>
<thead>
<tr>
<th>Test</th>
<th>Memory Model</th>
<th>Hygiene</th>
<th>Duration (ms)</th>
<th>W/Backoff (us)</th>
<th>Threads</th>
<th>Ops/Sec</th>
<th>EAGAIN%</th>
<th>NumKeys</th>
<th>Corrupt</th>
</tr>
</thead>
<tbody>
<tr>
<td>MRSW</td>
<td>in-memory</td>
<td>none</td>
<td>60000</td>
<td>0</td>
<td>63 + 1</td>
<td>3,259,500</td>
<td>23.72</td>
<td>20K</td>
<td>0</td>
</tr>
<tr>
<td>MRSW</td>
<td>im-memory</td>
<td>hybrid</td>
<td>60000</td>
<td>0</td>
<td>63 + 1</td>
<td>3,620,886</td>
<td>30.50</td>
<td>20K</td>
<td>0</td>
</tr>
<tr>
<td>MRSW</td>
<td>in-memory</td>
<td>none</td>
<td>60000</td>
<td>0</td>
<td>31 + 1</td>
<td>3,245,405</td>
<td>20.76</td>
<td>20K</td>
<td>0</td>
</tr>
<tr>
<td>MRSW</td>
<td>im-memory</td>
<td>hybrid</td>
<td>60000</td>
<td>0</td>
<td>31 + 1</td>
<td>3,273,807</td>
<td>20.60</td>
<td>20K</td>
<td>0</td>
</tr>
<tr>
<td>MRSW</td>
<td>in-memory</td>
<td>none</td>
<td>30000</td>
<td>0</td>
<td>15 + 1</td>
<td>4,094,896</td>
<td>31.94</td>
<td>10K</td>
<td>0</td>
</tr>
<tr>
<td>MRSW</td>
<td>file-backed</td>
<td>none</td>
<td>30000</td>
<td>0</td>
<td>15 + 1</td>
<td>4,768,989</td>
<td>29.63</td>
<td>10K</td>
<td>0</td>
</tr>
<tr>
<td>MRSW</td>
<td>file-backed</td>
<td>none</td>
<td>30000</td>
<td>150</td>
<td>15 + 1</td>
<td>2,992,652</td>
<td>13.94</td>
<td>10K</td>
<td>0</td>
</tr>
<tr>
<td>MRSW</td>
<td>file-backed</td>
<td>hybrid</td>
<td>30000</td>
<td>150</td>
<td>15 + 1</td>
<td>3,189,306</td>
<td>25.91</td>
<td>10K</td>
<td>0</td>
</tr>
</tbody>
</table>
<p>Keys were limited in file tests due to space and wear constraints, but an
in-memory reference is provided.</p>
<h2>A Note On Keyspaces</h2>
<p>The <code>key</code> part of <code>key -&gt; value</code> really is the key to success in your schema (no
puns intended, honestly).</p>
<p>The most basic use of a key is something like <code>foo</code>. And if you used tandem
slots, you'd be able to access foo, its velocity, its acceleration and its
jitter through <code>foo, foo.1, foo.2</code> and <code>foo.3</code> respectively.</p>
<p>That's easy enough, but what if <code>foo</code> collided with something else named <code>foo</code>
that you also wanted to track? That's why it's handy to prepend some kind of
namespace prior to the key. The author uses something like this:</p>
<p><code>type_name::experiment_name::run::variable::</code></p>
<p>Just .. <em>be kind to your future self when naming keys</em> and remember you can
change the order access operator if needed. You can change it to something that
won't appear in your normal data, like üí©; the separator is stored as
<code>SPL_ORDER_SEPARATOR</code> in <code>splinter.h</code>.</p>
<p>A little levity can make drab analysis marathons more tolerable. Send in the
poop, the clowns, the beds, or whatever it takes in the name of discovery.</p>
<h2>Some C Examples of Splinter During an "Average Work Day":</h2>
<h3>1. The Ingestor: Telemetry &amp; Atomic Global State</h3>
<p>This program simulates a high-frequency data loop. It records raw sensor values
while using splinter_integer_op to maintain a global "Event Count" that other
processes can monitor without needing a centralized lock:</p>
<pre><code class="language-c hljs"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">"splinter.h"</span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span>

<span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> {
    <span class="hljs-comment">// open pre-existing project bus</span>
    <span class="hljs-keyword">if</span> (splinter_open(<span class="hljs-string">"/dev/shm/physics_bus"</span>) != <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;

    <span class="hljs-comment">// use a BIGUINT to track global events across 100+ processes</span>
    <span class="hljs-comment">// this allows L3-speed atomic increments</span>
    <span class="hljs-type">uint64_t</span> inc = <span class="hljs-number">1</span>;
    <span class="hljs-type">double</span> sensor_val = <span class="hljs-number">0.0</span>;
    <span class="hljs-type">char</span> key[SPLINTER_KEY_MAX];

    <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; <span class="hljs-number">1000000</span>; i++) {
        sensor_val = read_spectrometer(); <span class="hljs-comment">// hypothetical hardware call</span>
        <span class="hljs-built_in">snprintf</span>(key, <span class="hljs-keyword">sizeof</span>(key), <span class="hljs-string">"sensor.alpha.%d"</span>, i % <span class="hljs-number">100</span>);

        <span class="hljs-comment">// write the telemetry point</span>
        splinter_set(key, &amp;sensor_val, <span class="hljs-keyword">sizeof</span>(sensor_val));

        <span class="hljs-comment">// atomic increment of the shared global counter</span>
        <span class="hljs-comment">// no mutex required; Splinter handles the atomic transition.</span>
        splinter_integer_op(<span class="hljs-string">"global_event_count"</span>, SPL_OP_INC, &amp;inc);
    }

    splinter_close();
    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<h3>2. The Analyzer: Vector State &amp; Bloom Signaling</h3>
<p>In this scenario, we process the telemetry and generate a state vector
(embedding). We use Bloom Labels to categorize particles. If a particle is
"Unstable," we tag it, which automatically pulses a specific Signal Group to
wake up a safety-shutdown process:</p>
<pre><code class="language-c hljs"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">"splinter.h"</span></span>

<span class="hljs-meta">#<span class="hljs-keyword">define</span> LABEL_UNSTABLE (1ULL &lt;&lt; 7) <span class="hljs-comment">// We use bit 7 for instability tracking</span></span>
<span class="hljs-meta">#<span class="hljs-keyword">define</span> GROUP_SAFETY    0          <span class="hljs-comment">// Signal group for the emergency process</span></span>

<span class="hljs-type">void</span> <span class="hljs-title function_">analyze_particle_state</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">char</span> *id)</span> {
    <span class="hljs-type">float</span> state_vector[SPL_EMBED_DIM];
    compute_particle_physics(id, state_vector); <span class="hljs-comment">// Hypothetical math</span>

    <span class="hljs-comment">// update the high-dimensional vector in shared memory</span>
    <span class="hljs-comment">// uses sequence locks to ensure readers don't get 'torn' vectors.</span>
    splinter_set_embedding(id, state_vector);

    <span class="hljs-comment">// some kind of anomaly detection (simulated)</span>
    <span class="hljs-keyword">if</span> (state_vector[<span class="hljs-number">0</span>] &gt; <span class="hljs-number">0.95f</span>) { 
        <span class="hljs-comment">// atomically-apply a Bloom label</span>
        <span class="hljs-comment">// this also triggers a pulse to the signal arena for anyone watching bit 7</span>
        splinter_set_label(id, LABEL_UNSTABLE);
        <span class="hljs-comment">// elusive splinter particle "sparticle" :P</span>
        <span class="hljs-built_in">printf</span>(<span class="hljs-string">"Sparticle %s is drifting! Label applied.\n"</span>, id);
    }
}
</code></pre>
<p>The speed isn't theoretical, though <a href="/splinter_performance">here's the math</a>
that explains it. FFI isn't scary when you just use C, and loadable modules are
the very next major feature on the way. Until then, the CLI is very hackable.</p>
<p>See also <code>splinference.cpp</code> as well as <code>splinter_stress.c</code> for examples of
batching and a multi-threaded mosh pit that never corrupts.</p>
<h3>3. The Monitor: NUMA-Local Watching</h3>
<p>This program represents the "Safety Observer." It runs on a specific NUMA node
to minimize memory latency. It doesn't poll; it waits for the Signal Arena to
indicate that an "Unstable" label was applied anywhere on the bus.</p>
<pre><code class="language-c hljs"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">"splinter.h"</span></span>
<span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;unistd.h&gt;</span></span>

<span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">()</span> {
    <span class="hljs-comment">// bind the bus to NUMA node 1 for local memory controller performance</span>
    splinter_open_numa(<span class="hljs-string">"/dev/shm/physics_bus"</span>, <span class="hljs-number">1</span>);

    <span class="hljs-comment">// map Bloom bit 7 (Unstable) to Signal Group 0 (Safety)</span>
    splinter_watch_label_register(LABEL_UNSTABLE, GROUP_SAFETY);

    <span class="hljs-type">uint64_t</span> last_count = splinter_get_signal_count(GROUP_SAFETY);

    <span class="hljs-keyword">while</span> (<span class="hljs-number">1</span>) {
        <span class="hljs-type">uint64_t</span> current = splinter_get_signal_count(GROUP_SAFETY);
        
        <span class="hljs-keyword">if</span> (current &gt; last_count) {
            <span class="hljs-comment">// a writer somewhere just set the UNSTABLE bit on a key</span>
            <span class="hljs-built_in">printf</span>(<span class="hljs-string">"SAFETY ALERT: %lu new unstable detections!\n"</span>, current - last_count);
            
            <span class="hljs-comment">// snapshot the header to check parse_failures or global epoch</span>
            <span class="hljs-type">splinter_header_snapshot_t</span> snap;
            splinter_get_header_snapshot(&amp;snap);
            
            last_count = current;
        }
        
        <span class="hljs-comment">// in the real world we would use epoll() on an eventfd</span>
        <span class="hljs-comment">// linked to the signal group. </span>
        usleep(<span class="hljs-number">500</span>); 
    }

    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;
}
</code></pre>
<h2>LLM Runtime / RAG / Training Uses</h2>
<p>Large Language Models are brilliant, but they suffer from severe amnesia. The
current industry solution to this is to bolt on a traditional Vector Database,
which forces the LLM to pause its thinking, serialize a JSON request, send it
over a network socket, and wait for a database to reply.</p>
<p>Splinter allows you to build a <strong>Semantic Hippocampus</strong>: a shared memory space
where the LLM‚Äôs short-term context and long-term memories live in the exact same
physical RAM, accessible instantly without a single <code>memcpy()</code>.</p>
<p>To understand how to use it, you don't need a PhD in linear algebra. You just
need to know your toolkit:</p>
<ul>
<li><strong>Cosine Similarity is your Steam Shovel:</strong> It grabs massive, general scoops
of memory that are semantically pointing in the same direction.</li>
<li><strong>Euclidean Distance is your Sifter:</strong> It shakes out the exact literal matches
from that massive bucket of context.</li>
<li><strong>Feature Flags are your Post-It Notes:</strong> You can slap a 64-bit integer onto
any memory slot to instantly track metadata (e.g.,
<code>flag_user_frustrated = 1</code>).</li>
<li><strong>Bloom Filters are your C-Style Tags:</strong> They allow you to instantly filter
the entire memory bus for specific concepts without scanning every individual
slot.</li>
</ul>
<p>So, what can you actually <em>build</em> with those tools?</p>
<h3>1. The Hallucination Governor (Preventing Narrative Lysis)</h3>
<p>Because Splinter operates at L3 cache speeds, it can sit <em>inside</em> the LLM's
auto-regressive generation loop. Using your Steam Shovel and Sifter, you can
constantly measure the "Tension" of the text the LLM is generating. If the LLM
starts speaking highly confidently about a subject where it has zero factual
grounding in its memory slots, a Splinter watcher detects that "Vacuum State."
It can physically halt the LLM mid-sentence before a hallucination escapes into
the user's terminal.</p>
<p>Logging uncertainty at inference and emitting special <code>&lt;UNC_explanation&gt;</code> tokens
lets you watch for these events <em>very</em> specifically. Custom information physics
engines can provide even greater accuracy, such as those that Splinter is being
used to research.</p>
<h3>2. True Zero-Latency RAG (Retrieval-Augmented Generation)</h3>
<p>In traditional RAG, embedding vectors are serialized and dragged across the
kernel boundary. With Splinter, the inference engine (like <code>llama.cpp</code>) simply
casts a raw C-pointer to the L3 cache. When a user asks a 70B parameter model a
question, the context injection happens instantly. You are feeding the AI its
own memories at the speed of the hardware bus.</p>
<h3>3. User-space Conversational Memory</h3>
<p>Splinter gives you a cheap semantic key-&gt;value store for personalizations
that would work blazingly fast persistently, too. If ctags style bloom isn't
enough, a 1024x1024 store just for their needs works perfectly.</p>
<h2>Testing Splinter</h2>
<p>You can run Splinter's tests using <code>make tests</code>. If you have enabled Valgrind
integration, splinter's unit and integration tests will also be scrutinized
for leaks and access errors. For less than 1k lines of total core code,
Splinter is extremely well-tested. Splinter uses CMake's test runner with
a few scripts at the end.</p>
<p>Performance benchmarks can be obtained with <code>splinter_stress</code> and
<code>splinterp_stress</code> for in-memory and file-backed respectively, as shown above.</p>

    </main>
    <footer>
    Want To Help Fund Development?<br>
    <div style="text-align: center; margin: 1em auto">
      <a href="https://www.buymeacoffee.com/timthepost" id="donateLink" target="_blank">
        <img src="https://cdn.buymeacoffee.com/buttons/v2/default-blue.png" alt="Buy Me A Coffee" title="I run on coffee!" style="height: 60px !important; width: 217px !important">
      </a>
    </div>
    Built BBS Ugly ‚ù§Ô∏è With BBS Love<br>
    </footer>
  

</body></html>