<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0">
    <title>Some Math Behind Splinter's Claims - Splinter Vector KV Substrate</title>
    <meta name="color-scheme" content="dark">
    <meta name="google-site-verification" content="cFJqGxOZGxw1APr0yrQthB4Ml5vFuMNBu39xMS4BYJI">
    <link rel="stylesheet" media="(prefers-color-scheme:dark)" href="https://cdn.jsdelivr.net/npm/@shoelace-style/shoelace@2.20.1/cdn/themes/dark.css" onload="document.documentElement.classList.add('sl-theme-dark');">
    <link rel="stylesheet" href="/style.css">
    <link rel="canonical" href="https://splinterhq.github.io/splinter_performance/">
    <script id="MathJax-script" async="" src="https://cdn.jsdelivr.net/npm/mathjax@4/tex-mml-chtml.js">
    </script>
  <meta property="og:type" content="website">
<meta property="og:site_name" content="Splinter Vector KV Substrate">
<meta property="og:locale" content="en">
<meta property="og:description" content="A physics-based breakdown of Splinter's performance, analyzing Cycles Per Operation to demonstrate its massive efficiency gains over traditional DBs.">
<meta property="og:url" content="https://splinterhq.github.io/splinter_performance/">
<meta property="og:image" content="https://splinterhq.github.io/uploads/favicon.svg">
<meta name="twitter:card" content="summary">
<meta name="description" content="A physics-based breakdown of Splinter's performance, analyzing Cycles Per Operation to demonstrate its massive efficiency gains over traditional DBs.">
<meta name="keywords" content="Cycles Per Operation, IPC Performance, Lock-Free Benchmarks, Socket Tax, Hardware Optimization">
<meta name="robots" content="index, follow">
<meta name="generator" content="Lume 3.1.1">
<link rel="icon" sizes="32x32" href="/favicon.ico">
<link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
<link rel="icon" sizes="any" href="/uploads/favicon.svg" type="image/svg+xml">
</head>
  <body>
    <main class="container">
      <nav class="top-nav" id="nav">
        <a href="/">INTRO</a>
        <a href="/core">CORE</a>
        <a href="/cli">CLI</a>
        <a href="/shards">SHARDS</a>
        <a href="/bindings">BINDINGS</a>
        <a href="https://github.com/splinterhq/libsplinter/tree/main" target="_blank">CODE</a>
      </nav>
      <div style="clear: both"></div>
      <h1>Some Math Behind Splinter's Claims</h1>
<p>We must guard our time. This is especially true for researchers, where system
sluggishness can literally sabotage discovery and cause months or years of
setbacks. Because Splinter makes some rather audacious performance claims, it
should back them up with physics, not just benchmarks.</p>
<p>This explanation is not an attempt to start a competition with beloved
industry-standard tools. We compare against SQLite and Redis because <strong>they are
the only widely known frames of reference available</strong>. Splinter’s author
considers both to be inspirational symphonies written in code.</p>
<p>But sometimes, you just need a piccolo, not an orchestra.</p>
<p><em><strong>TL;DR: It's physics.</strong></em> Splinter divorced socket and mutex overhead, shrank
the logic to fit entirely inside the instruction cache, and aligned I/O to
prevent false sharing. It is designed to capture data first and backfill what
can be extrapolated later.</p>
<h2><strong>The Efficiency Gap: Instruction Physics vs. Socket Tax</strong></h2>
<p>To justify a <strong>Passive Substrate</strong> (Splinter) over <strong>Active Middleware</strong>
(Redis/SQLite), we analyze the <strong>Cycles Per Operation (CPO)</strong>. This metric
reveals how much "work" the CPU must perform to move a single piece of data.</p>
<p>There are, of course, going to be many different variances of exactly what has
to happen for a connection to be initiated, what kind of security layers are in
place, what kind of observation the kernel is also helping with, and what else
is causing preemption on the system. So, we start as close as we can get to the
<em>actual</em> worst case, and extrapolate a conservative best case from there.</p>
<h3><strong>1. The Baseline: Throttled i3-1115G4 (3.0 GHz)</strong></h3>
<p>At 3.0 GHz, each core has a budget of <strong>3,000,000,000 cycles/sec</strong>.</p>
<table>
<thead>
<tr>
<th style="text-align:left">Substrate</th>
<th style="text-align:left">Ops/Sec</th>
<th style="text-align:left">Cycles Per Operation (CPO)</th>
<th style="text-align:left">Logic</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left"><strong>Traditional (SQLite/Redis)</strong></td>
<td style="text-align:left">130,000</td>
<td style="text-align:left"><strong>~23,076</strong></td>
<td style="text-align:left">Throttled by context switches, syscalls, and the Kernel boundary.</td>
</tr>
<tr>
<td style="text-align:left"><strong>Splinter (Standard)</strong></td>
<td style="text-align:left">3,200,000</td>
<td style="text-align:left"><strong>~937</strong></td>
<td style="text-align:left">Operates in userspace via <code>mmap</code>, avoiding the "Socket Tax."</td>
</tr>
<tr>
<td style="text-align:left"><strong>Splinter (Projected Pinning)</strong></td>
<td style="text-align:left">10,000,000+</td>
<td style="text-align:left"><strong>&lt;300</strong></td>
<td style="text-align:left">Limited only by memory bus throttling and the 6MB L3 cache.</td>
</tr>
</tbody>
</table>
<h3><strong>2. The AMD Extrapolation: Proportional Scaling</strong></h3>
<p>On a modern AMD rig (e.g., Zen 4/5), we are no longer memory-throttled. We
benefit from 128MB+ of L3 cache and significantly higher IPC (Instructions Per
Cycle).</p>
<ul>
<li><strong>Redis Ceiling:</strong> Even on high-end hardware, Redis is bound by the <strong>Kernel's
interrupt latency</strong>. Even at 500k ops/sec, it still spends <strong>~10,000
cycles/op</strong> due to the inescapable cost of the network stack.</li>
<li><strong>Splinter (NUMA-Pinned):</strong> With the manifold residing entirely in a massive
L3 cache and pinned to a high-bandwidth Infinity Fabric lane, we expect the
CPO to drop into the single digits.</li>
</ul>
<h3><strong>3. The Math of the Claim</strong></h3>
<p>If we conservatively estimate the AMD rig hits <strong>500,000,000 ops/sec</strong> (0.5
Billion), the physics becomes undeniable:</p>
<p>$$CPO_{AMD} = \frac{5,000,000,000 \text{ cycles/sec (est. clock)}}{500,000,000 \text{ ops/sec}} = \mathbf{10 \text{ cycles/op}}$$</p>
<p>This represents a <strong>2,300x improvement in efficiency</strong> over the traditional i3
baseline (23,076 / 10).</p>
<h2><strong>Summary for Researchers</strong></h2>
<p>While traditional architectures are restricted by a <strong>Series of Jerks</strong>—our term
for the erratic overhead of interrupts and context switching, Splinter functions
as a <strong>Laminar Flow Substrate</strong>. On commodity hardware, Splinter already
outperforms Redis by <strong>16x</strong> and SQLite3 by <strong>33x</strong>, despite memory throttling.</p>
<p>Moving to an AMD rig with NUMA-pinning will allow us to achieve a projected <strong>10
cycles per operation</strong>. At this scale, Splinter isn't just "faster"—it is
operating at the physical limit of the silicon, achieving <strong>~2,300 times the
efficiency</strong> of standard middleware by removing the "Socket Tax" entirely.</p>
<p><strong>Baseline: i3-1115G4 @ 3.0GHz</strong></p>
<p>Traditional Middleware (130k ops/sec):
$$\frac{3 \times 10^9}{130,000} \approx 23,076 \text{ cycles/op}$$</p>
<p>Splinter Standard (3.2M ops/sec):
$$\frac{3 \times 10^9}{3,200,000} \approx 937 \text{ cycles/op}$$</p>
<p><strong>Projected: AMD Rig (NUMA-Pinned @ 5.0GHz Clock):</strong></p>
<p>We're in the process of seeking/acquiring additional funding for development and
plan to transition to "big iron" now that we're certain we can support weaker
memory models sufficiently.</p>
<p>To help substantiate the need to grow the computational lab, we had to consider
what we could do (GDELT is massive) with higher-resolution samplings. We knew it
was high but the math was a little startling:</p>
<p><strong>Splinter Conservative Estimate (500M ops/sec):</strong></p>
<p>$$\frac{5 \times 10^9}{500,000,000} = 10 \text{ cycles/op}$$</p>
<p><strong>The Efficiency Delta:</strong></p>
<p>The jump from <strong>23,076</strong> cycles to <strong>10</strong> cycles per operation represents a
<strong>2,300x</strong> reduction in the computational energy required to audit the manifolds
examined in high-resolution research.</p>
<p>We expect this will be the experience of teams working with massive amounts of
vectors, or timing Rank 2+ tensor measurements (as we do) and invite additional
use as well as scrutiny and feedback.</p>
<p>If you're still here, you might be interested in reading about <a href="/splinter_and_linux">why Splinter
and Linux get along so well</a>.</p>

    </main>
    <footer>
    Want To Help Fund Development?<br>
    <div style="text-align: center; margin: 1em auto">
      <a href="https://www.buymeacoffee.com/timthepost" id="donateLink" target="_blank">
        <img src="https://cdn.buymeacoffee.com/buttons/v2/default-blue.png" alt="Buy Me A Coffee" title="I run on coffee!" style="height: 60px !important; width: 217px !important">
      </a>
    </div>
    <span>Terminal ❤️ Nostalgia</span><br>
    </footer>
  

</body></html>